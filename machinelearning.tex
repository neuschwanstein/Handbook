\part{Machine Learning}


\begin{outline}
  \1 In \textbf{logistic regression}, the following model is often adopted:
  \begin{align*}
    P(y=1|x) &= \frac{1}{1+\exp(-\theta^Tx)} = \sigma(\theta^Tx),\\
    P(y=0|x) &= 1 - \sigma(\theta^Tx)
  \end{align*}
  with $\sigma(x)$ the \textbf{sigmoid function}.

  \1 The \textbf{loss function} of the logistic regression is given by 
  \begin{equation*}
    J(\theta) = -\sum_i (y^{(i)}\log(h(x^{(i)})) + (1-y^{(i)})\log(1-h(x^{(i)}))).
  \end{equation*}

\end{outline}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "handbook"
%%% End:
